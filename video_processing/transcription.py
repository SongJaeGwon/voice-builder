from video_processing import json, openai, get_file_path
from config import OPEN_AI_TOKEN

openai.api_key = OPEN_AI_TOKEN

def transcribe_audio_whisper(audio_file, model="whisper-1"):
    client = openai.OpenAI(api_key=OPEN_AI_TOKEN)

    # ğŸ”¹ OpenAI Whisper API ìš”ì²­
    with open(audio_file, "rb") as file:
        response = client.audio.transcriptions.create(
            model=model,
            file=file,
            response_format="verbose_json",
        )

    response_json = response.model_dump()
    output_path = get_file_path("transcription_whisper.json")

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(response_json, f, indent=4, ensure_ascii=False)

    return response_json

def refine_srt_with_gpt(srt_file_path, output_srt_path):
    with open(srt_file_path, "r", encoding="utf-8") as file:
        srt_content = file.read()

    prompt = f"""
    ë‹¤ìŒì€ ìë§‰ íŒŒì¼ì˜ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ìë§‰ì„ ë” ìì—°ìŠ¤ëŸ½ê³  ë¬¸ë§¥ì— ë§ê²Œ ìˆ˜ì •í•´ ì£¼ì„¸ìš”.
    ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ë³€ê²½í•˜ì§€ ì•Šê³ , ë” ì½ê¸° ì‰½ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë“¬ì–´ ì£¼ì„¸ìš”.

    **SRT í˜•ì‹ ìœ ì§€ (ë²ˆí˜¸, íƒ€ì„ìŠ¤íƒ¬í”„, í…ìŠ¤íŠ¸ë§Œ í¬í•¨)**  
    **ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸(ì˜ˆ: ì½”ë“œ ë¸”ë¡, ```plaintext ë“±)ëŠ” í¬í•¨í•˜ì§€ ë§ ê²ƒ**  
    **ìì—°ìŠ¤ëŸ½ê³  ê°€ë…ì„± ì¢‹ì€ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜**

    -- ì›ë³¸ ìë§‰ --
    {srt_content}

    -- ë³€í™˜ëœ ìë§‰ --
    """

    client = openai.OpenAI(api_key=OPEN_AI_TOKEN)

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "system", "content": "ë‹¹ì‹ ì€ ìë§‰ì„ ë‹¤ë“¬ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                  {"role": "user", "content": prompt}],
        temperature=0.7
    )

    refined_srt = response.choices[0].message.content.strip()

    with open(output_srt_path, "w", encoding="utf-8") as file:
        file.write(refined_srt)

    return output_srt_path